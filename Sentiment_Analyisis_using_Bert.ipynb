{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n"
      ],
      "metadata": {
        "id": "e80uE574249O"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Load the dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/twitter_data.csv', encoding='ISO-8859-1', names=['target', 'ids', 'date', 'flag', 'user', 'text'])\n",
        "df = df.sample(n=100000, random_state=42)\n",
        "\n"
      ],
      "metadata": {
        "id": "Qp26r_Vq2-bi"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Preprocess the data\n",
        "# Remove unnecessary columns\n",
        "df = df[['target', 'text']]\n",
        "# Map target values to 0, 1, 2 (assuming your target values are 0, 2, 4)\n",
        "df['target'] = df['target'].map({0: 0, 2: 1, 4: 2})\n",
        "\n",
        "# Step 4: Split the dataset into training and testing sets\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(df['text'], df['target'], test_size=0.2, random_state=42)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYPor2c3cfk6",
        "outputId": "e454c6a9-6c47-44ac-9e6b-1855266e3ce4"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-b2326950238d>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['target'] = df['target'].map({0: 0, 2: 1, 4: 2})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Tokenize and encode the text data\n",
        "max_len = 64  # Maximum sequence length\n",
        "max_words = 10000  # Maximum number of words in the tokenizer's vocabulary\n",
        "\n",
        "# Tokenize the text data\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "# Tokenize and encode the text data using BERT tokenizer\n",
        "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=max_len, return_tensors='pt')\n",
        "test_encodings = tokenizer(list(test_texts), truncation=True, padding=True, max_length=max_len, return_tensors='pt')\n",
        "\n"
      ],
      "metadata": {
        "id": "tY7i9BiL4VwU"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
        "test_labels_encoded = label_encoder.transform(test_labels)\n",
        "\n",
        "# Step 6: Create PyTorch datasets for BERT\n",
        "train_dataset_bert = TensorDataset(train_encodings['input_ids'], train_encodings['attention_mask'], torch.tensor(train_labels_encoded))\n",
        "test_dataset_bert = TensorDataset(test_encodings['input_ids'], test_encodings['attention_mask'], torch.tensor(test_labels_encoded))\n",
        "\n",
        "batch_size_bert = 32\n",
        "train_loader_bert = DataLoader(train_dataset_bert, batch_size=batch_size_bert, sampler=RandomSampler(train_dataset_bert))\n",
        "test_loader_bert = DataLoader(test_dataset_bert, batch_size=batch_size_bert, sampler=SequentialSampler(test_dataset_bert))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VmXfaNQJ47Yd"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Load the pre-trained BERT model for sequence classification\n",
        "model_bert = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n",
        "\n",
        "# Step 9: Set up optimizer and scheduler\n",
        "optimizer_bert = AdamW(model_bert.parameters(), lr=2e-5, eps=1e-8)\n",
        "epochs_bert = 3\n",
        "total_steps_bert = len(train_loader_bert) * epochs_bert\n",
        "scheduler_bert = get_linear_schedule_with_warmup(optimizer_bert, num_warmup_steps=0, num_training_steps=total_steps_bert)\n",
        "\n"
      ],
      "metadata": {
        "id": "bqOH44wK4_1_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c0ab998-ca6c-4ae3-c761-d1be1835dd06"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 10: Fine-tune BERT model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model_bert.to(device)\n",
        "\n",
        "for epoch in range(epochs_bert):\n",
        "    model_bert.train()\n",
        "    total_train_loss = 0\n",
        "\n",
        "    for batch in tqdm(train_loader_bert, desc=f'Epoch {epoch + 1}', leave=False):\n",
        "        input_ids = batch[0].to(device)\n",
        "        attention_mask = batch[1].to(device)\n",
        "        labels = batch[2].to(device)\n",
        "\n",
        "        model_bert.zero_grad()\n",
        "        outputs = model_bert(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model_bert.parameters(), 1.0)\n",
        "        optimizer_bert.step()\n",
        "        scheduler_bert.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_loader_bert)\n",
        "    print(f'Training loss: {avg_train_loss}')\n"
      ],
      "metadata": {
        "id": "Yx6SrQ57615o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e32c255-78bc-489b-b61c-3f6d8c54280a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.3901797324448824\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.27158005678057673\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                            "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.18474914499670267\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Evaluate the model on the test set\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from transformers import BertTokenizer\n",
        "model_bert.eval()\n",
        "predictions = []\n",
        "true_labels = []\n",
        "\n",
        "for batch in tqdm(test_loader_bert, desc='Evaluating'):\n",
        "    input_ids = batch[0].to(device)\n",
        "    attention_mask = batch[1].to(device)\n",
        "    labels = batch[2]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model_bert(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    predictions.extend(np.argmax(logits, axis=1))\n",
        "    true_labels.extend(labels.numpy())\n",
        "\n"
      ],
      "metadata": {
        "id": "Tdk7qELQ7WDK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "c4ceaee4-ab08-4567-bf13-f6a0bc215aa3"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 625/625 [01:12<00:00,  8.61it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'numpy.int64' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-5b96eb08d939>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Step 9: Calculate accuracy and other metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Accuracy: {accuracy}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m         \u001b[0mlongest_last_line_heading\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"weighted avg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m         \u001b[0mname_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m         \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlongest_last_line_heading\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdigits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m         \u001b[0mhead_fmt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"{:>{width}s} \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" {:>9}\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m         \u001b[0mlongest_last_line_heading\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"weighted avg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m         \u001b[0mname_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m         \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlongest_last_line_heading\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdigits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m         \u001b[0mhead_fmt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"{:>{width}s} \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" {:>9}\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'numpy.int64' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Calculate accuracy and other metrics\n",
        "accuracy = accuracy_score(true_labels, predictions)\n",
        "report = classification_report(true_labels, predictions, target_names=['Negative', 'Positive'])\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGPtLK9atSsR",
        "outputId": "4c2a4227-35b3-44da-abcf-263bc7978c27"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8458\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.84      0.86      0.85      9995\n",
            "    Positive       0.85      0.83      0.84     10005\n",
            "\n",
            "    accuracy                           0.85     20000\n",
            "   macro avg       0.85      0.85      0.85     20000\n",
            "weighted avg       0.85      0.85      0.85     20000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for predicting sentiment of a given text\n",
        "def predict_sentiment(text):\n",
        "    encoded_text = tokenizer_bert.encode_plus(\n",
        "        text,\n",
        "        max_length=max_len,\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "    input_ids = encoded_text['input_ids'].to(device)\n",
        "    attention_mask = encoded_text['attention_mask'].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model_bert(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    logits = output.logits\n",
        "    predicted_class = torch.argmax(logits, dim=1).cpu().item()\n",
        "\n",
        "    return label_encoder.classes_[predicted_class]\n",
        "\n",
        "# Test the predict_sentiment function with user input\n",
        "user_input = \"I love this movie!\"\n",
        "predicted_sentiment = predict_sentiment(user_input)\n",
        "print(f'User input: \"{user_input}\"')\n",
        "print(f'Predicted sentiment: {predicted_sentiment}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIebpcgGdyeZ",
        "outputId": "a6463479-7313-4d82-809c-f28e73fc0e5d"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User input: \"I love this movie!\"\n",
            "Predicted sentiment: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the predict_sentiment function with user input\n",
        "user_input = \"I hate this movie!\"\n",
        "predicted_sentiment = predict_sentiment(user_input)\n",
        "print(f'User input: \"{user_input}\"')\n",
        "print(f'Predicted sentiment: {predicted_sentiment}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfxScOyItoa0",
        "outputId": "53a5053f-dad6-4357-a104-33a1a774a76c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User input: \"I hate this movie!\"\n",
            "Predicted sentiment: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the predict_sentiment function with user input\n",
        "# user_input = \"I love the way that the movie sucks!\"\n",
        "user_input = \"a woman with red hair in the rain with a dog in the background and a man in a red shirt and a dog attacked the man in the rain \"\n",
        "predicted_sentiment = predict_sentiment(user_input)\n",
        "print(f'User input: \"{user_input}\"')\n",
        "print(f'Predicted sentiment: {predicted_sentiment}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Je1qPlcKtt2p",
        "outputId": "3b1e5c25-8abe-4a2f-ea9e-75a291d65a43"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User input: \"a woman with red hair in the rain with a dog in the background and a man in a red shirt and a dog attacked the man in the rain \"\n",
            "Predicted sentiment: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_save_name = 'sentiment_BERT.pt'\n",
        "path = F\"/content/drive/MyDrive/{model_save_name}\"\n",
        "torch.save(model_bert.state_dict(), path)"
      ],
      "metadata": {
        "id": "5d-yAdaruL-1"
      },
      "execution_count": 54,
      "outputs": []
    }
  ]
}